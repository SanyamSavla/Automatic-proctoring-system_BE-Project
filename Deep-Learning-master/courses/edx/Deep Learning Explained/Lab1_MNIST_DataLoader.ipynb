{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Lab 1: MNIST Data Loader\n",
    "\n",
    "This notebook is the first lab of the \"Deep Learning Explained\" course.  It is derived from  the tutorial numbered CNTK_103A in the CNTK repository.  This notebook is used to download and pre-process the [MNIST][] digit images to be used for building different models to recognize handwritten digits.   \n",
    "\n",
    "** Note: ** This notebook must be run to completion before the other course notebooks can be run.\n",
    "\n",
    "[MNIST]: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the relevant modules to be used later\n",
    "from __future__ import print_function\n",
    "import gzip\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "try: \n",
    "    from urllib.request import urlretrieve \n",
    "except ImportError: \n",
    "    from urllib import urlretrieve\n",
    "\n",
    "# Config matplotlib for inline plotting\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data download\n",
    "\n",
    "We will download the data onto the local machine. The MNIST database is a standard set of handwritten digits that has been widely used for training and testing of machine learning algorithms. It has a training set of 60,000 images and a test set of 10,000 images with each image being 28 x 28 grayscale pixels. This set is easy to use visualize and train on any computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to load MNIST images and unpack into train and test set.\n",
    "# - loadData reads image data and formats into a 28x28 long array\n",
    "# - loadLabels reads the corresponding labels data, 1 for each image\n",
    "# - load packs the downloaded image and labels data into a combined format to be read later by \n",
    "#   CNTK text reader \n",
    "\n",
    "def loadData(src, cimg):\n",
    "    print ('Downloading ' + src)\n",
    "    gzfname, h = urlretrieve(src, './delete.me')\n",
    "    print ('Done.')\n",
    "    try:\n",
    "        with gzip.open(gzfname) as gz:\n",
    "            n = struct.unpack('I', gz.read(4))\n",
    "            # Read magic number.\n",
    "            if n[0] != 0x3080000:\n",
    "                raise Exception('Invalid file: unexpected magic number.')\n",
    "            # Read number of entries.\n",
    "            n = struct.unpack('>I', gz.read(4))[0]\n",
    "            if n != cimg:\n",
    "                raise Exception('Invalid file: expected {0} entries.'.format(cimg))\n",
    "            crow = struct.unpack('>I', gz.read(4))[0]\n",
    "            ccol = struct.unpack('>I', gz.read(4))[0]\n",
    "            if crow != 28 or ccol != 28:\n",
    "                raise Exception('Invalid file: expected 28 rows/cols per image.')\n",
    "            # Read data.\n",
    "            res = np.fromstring(gz.read(cimg * crow * ccol), dtype = np.uint8)\n",
    "    finally:\n",
    "        os.remove(gzfname)\n",
    "    return res.reshape((cimg, crow * ccol))\n",
    "\n",
    "def loadLabels(src, cimg):\n",
    "    print ('Downloading ' + src)\n",
    "    gzfname, h = urlretrieve(src, './delete.me')\n",
    "    print ('Done.')\n",
    "    try:\n",
    "        with gzip.open(gzfname) as gz:\n",
    "            n = struct.unpack('I', gz.read(4))\n",
    "            # Read magic number.\n",
    "            if n[0] != 0x1080000:\n",
    "                raise Exception('Invalid file: unexpected magic number.')\n",
    "            # Read number of entries.\n",
    "            n = struct.unpack('>I', gz.read(4))\n",
    "            if n[0] != cimg:\n",
    "                raise Exception('Invalid file: expected {0} rows.'.format(cimg))\n",
    "            # Read labels.\n",
    "            res = np.fromstring(gz.read(cimg), dtype = np.uint8)\n",
    "    finally:\n",
    "        os.remove(gzfname)\n",
    "    return res.reshape((cimg, 1))\n",
    "\n",
    "def try_download(dataSrc, labelsSrc, cimg):\n",
    "    data = loadData(dataSrc, cimg)\n",
    "    labels = loadLabels(labelsSrc, cimg)\n",
    "    return np.hstack((data, labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the data\n",
    "\n",
    "In the following code, we use the functions defined above to download and unzip the MNIST data into memory.  The training set has 60000 images while the test set has 10000 images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train data\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnaldo\\Miniconda3\\envs\\edx\\lib\\site-packages\\ipykernel_launcher.py:26: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Done.\n",
      "Downloading test data\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arnaldo\\Miniconda3\\envs\\edx\\lib\\site-packages\\ipykernel_launcher.py:46: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# URLs for the train image and labels data\n",
    "url_train_image = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
    "url_train_labels = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
    "num_train_samples = 60000\n",
    "\n",
    "print(\"Downloading train data\")\n",
    "train = try_download(url_train_image, url_train_labels, num_train_samples)\n",
    "\n",
    "\n",
    "url_test_image = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
    "url_test_labels = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "num_test_samples = 10000\n",
    "\n",
    "print(\"Downloading test data\")\n",
    "test = try_download(url_test_image, url_test_labels, num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the data\n",
    "Here, we use matplotlib to display one of the training images and it's associated label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Label:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot a random image\n",
    "sample_number = 5001\n",
    "plt.imshow(train[sample_number,:-1].reshape(28,28), cmap=\"gray_r\")\n",
    "plt.axis('off')\n",
    "print(\"Image Label: \", train[sample_number,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the images\n",
    "\n",
    "Save the images in a local directory. While saving the data we flatten the images to a vector (28x28 image pixels becomes an array of length 784 data points).\n",
    "\n",
    "![mnist-input](https://www.cntk.ai/jup/cntk103a_MNIST_input.png)\n",
    "\n",
    "The labels are encoded as [1-hot][] encoding (label of 3 with 10 digits becomes `0001000000`, where the first index corresponds to digit `0` and the last one corresponds to digit `9`.\n",
    "\n",
    "![mnist-label](https://www.cntk.ai/jup/cntk103a_onehot.png)\n",
    "\n",
    "[1-hot]: https://en.wikipedia.org/wiki/One-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data files into a format compatible with CNTK text reader\n",
    "def savetxt(filename, ndarray):\n",
    "    dir = os.path.dirname(filename)\n",
    "\n",
    "    if not os.path.exists(dir):\n",
    "        os.makedirs(dir)\n",
    "\n",
    "    if not os.path.isfile(filename):\n",
    "        print(\"Saving\", filename )\n",
    "        with open(filename, 'w') as f:\n",
    "            labels = list(map(' '.join, np.eye(10, dtype=np.uint).astype(str)))\n",
    "            for row in ndarray:\n",
    "                row_str = row.astype(str)\n",
    "                label_str = labels[row[-1]]\n",
    "                feature_str = ' '.join(row_str[:-1])\n",
    "                f.write('|labels {} |features {}\\n'.format(label_str, feature_str))\n",
    "    else:\n",
    "        print(\"File already exists\", filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train text file...\n",
      "Saving data\\MNIST\\Train-28x28_cntk_text.txt\n",
      "Writing test text file...\n",
      "Saving data\\MNIST\\Test-28x28_cntk_text.txt\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Save the train and test files (prefer our default path for the data)\n",
    "data_dir = os.path.join(\"..\", \"Examples\", \"Image\", \"DataSets\", \"MNIST\")\n",
    "if not os.path.exists(data_dir):\n",
    "    data_dir = os.path.join(\"data\", \"MNIST\")\n",
    "\n",
    "print ('Writing train text file...')\n",
    "savetxt(os.path.join(data_dir, \"Train-28x28_cntk_text.txt\"), train)\n",
    "\n",
    "print ('Writing test text file...')\n",
    "savetxt(os.path.join(data_dir, \"Test-28x28_cntk_text.txt\"), test)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optional: Suggested Explorations** \n",
    "\n",
    "One can do data manipulations to improve the performance of a machine learning system. I suggest you first use the data generated so far and complete Lab 2- 4 labs. Once you have a baseline with classifying the data in its original form, now use the different data manipulation techniques to further improve the model.\n",
    "\n",
    "There are several ways data alterations can be performed. CNTK readers automate a lot of these actions for you. However, to get a feel for how these transforms can impact training and test accuracies, I strongly encourage individuals to try one or more of data perturbation.\n",
    "\n",
    "- Shuffle the training data rows to create a different set of training images.  Be sure to shuffle each image in the same way.   Hint: Use `permute_indices = np.random.permutation(train.shape[0])`. Then run Lab 2-4 with this newly permuted data.\n",
    "- Adding noise to the data can often improve (lower) the [generalization error][]. You can augment the training set by adding  noise (generated with numpy, hint: use `numpy.random`) to the training images. \n",
    "- Distort the images with [affine transformation][] (translations or rotations)\n",
    "\n",
    "[generalization error]: https://en.wikipedia.org/wiki/Generalization_error\n",
    "[affine transformation]: https://en.wikipedia.org/wiki/Affine_transformation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
